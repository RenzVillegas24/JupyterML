{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Optimal Parameters for Machine Learning Models\n",
    "### Dr. Robert G. de Luna, PECE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "- How to search for an **optimal tuning parameter**?\n",
    "- How do you search for **multiple tuning parameters** at once?\n",
    "- What do you do with those tuning parameters before making **real predictions**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO CHECK THE VERSION OF LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print('Python: {}'.format(sys.version))\n",
    "# scipy\n",
    "import scipy\n",
    "print('scipy: {}'.format(scipy.__version__))\n",
    "# numpy\n",
    "import numpy\n",
    "print('numpy: {}'.format(numpy.__version__))\n",
    "# matplotlib\n",
    "import matplotlib\n",
    "print('matplotlib: {}'.format(matplotlib.__version__))\n",
    "# pandas\n",
    "import pandas\n",
    "print('pandas: {}'.format(pandas.__version__))\n",
    "# scikit-learn\n",
    "import sklearn\n",
    "print('sklearn: {}'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO LOAD THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pandas.read_csv('Herbal_Plants.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DETERMINE THE DIMENSIONS OF THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO PEEK AT THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO SEE THE STATISTICAL SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO SEE THE CLASS DISTRIBUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.groupby('Herbal').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO SHOW THE UNIVARIATE PLOT (BOX and WHISKER PLOTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.plot(kind='box', subplots=False, layout=(1,5), sharex=False, sharey=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TO SHOW THE HISTOGRAM FOR THE DISTRIBUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOR THE MULTIVARIATE PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the Scatter Plot Matrix\n",
    "from pandas.plotting import scatter_matrix\n",
    "scatter_matrix(dataset)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO CREATE THE MATRIX OF INDEPENDENT VARIABLE, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, :-1].values\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO CREATE THE MATRIX OF DEPENDENT VARIABLE, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = dataset.iloc[:, 5].values\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO ENCODE THE CATEGORICAL DATA IN THE DEPENDENT VARIABLE, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder \n",
    "labelencoder_Y = LabelEncoder()\n",
    "Y = labelencoder_Y.fit_transform(Y)\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TO SPLIT THE DATASET INTO TRAINING DATASET AND TESTING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Show the Shapes of X and Y Data\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Show the Shapes of the New X Objects\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Show the Shapes of the New Y Objects\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TO IMPORT DIFFERENT MACHINE LEARNING MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### To Build Different Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('LR', LogisticRegression(max_iter=1000000)))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "models.append(('NN', MLPClassifier()))\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To Evaluate Each Model in Turn Using Default Parameters of All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Test Options and Evaluation Metric\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in models:\n",
    "\tk_Fold = StratifiedKFold(n_splits=10, shuffle=True, random_state=None)\n",
    "\tcv_results = cross_val_score(model, X, Y, cv=k_Fold, scoring='accuracy')\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tprinted_results = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "\tprint(printed_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To Select the Best Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure()\n",
    "figure.suptitle('Algorithm Comparison')\n",
    "axis = figure.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "axis.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. To Create the Logistic Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Instantiate the Model (Using the Default Parameters)\n",
    "logistic_regression = LogisticRegression(max_iter=100000, random_state=0)\n",
    "\n",
    "# To Fit the Training Dataset into Logistic Regression Model\n",
    "logistic_regression.fit(X_train, Y_train)\n",
    "\n",
    "# To Predict the Output of the Testing Dataset\n",
    "Y_predict_LogReg = logistic_regression.predict(X_test)\n",
    "Y_predict_LogReg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### To Evaluate the Performance of the Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Show the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(Y_test, Y_predict_LogReg)\n",
    "\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(confusion_matrix, annot=True)\n",
    "plt.xlabel(\"Predicted Value\")\n",
    "plt.ylabel(\"Actual Value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the Classification Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "classification_accuracy = accuracy_score(Y_test, Y_predict_LogReg)\n",
    "print('Classification Accuracy: %.4f'\n",
    "      % classification_accuracy)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"CLASSIFICATION REPORT:\")\n",
    "print(classification_report(Y_test, Y_predict_LogReg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying GridSearchCV to find the Best Parameters for the Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search can be thought of as an exhaustive search for selecting a model. In Grid Search, the data scientist sets up a grid of hyperparameter values and for each combination, trains a model and scores on the testing data. In this approach, every combination of hyperparameter values is tried which can be very inefficient. For example, searching 20 different parameter values for each of 4 parameters will require 160,000 trials of cross-validation. This equates to 1,600,000 model fits and 1,600,000 predictions if 10-fold cross validation is used. While Scikit Learn offers the GridSearchCV function to simplify the process, it would be an extremely costly execution both in computing power and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Import the StratifiedKFold Class\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "k_Fold = StratifiedKFold (n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "# To Import the GridSearch Class\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# To Set Parameters to be Optimized Under the Logistic Regression Model\n",
    "parameters = [{'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'penalty': ['l1'], 'solver': ['liblinear','saga']},\n",
    "              {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'penalty': ['l1', 'l2'], 'solver': ['newton-cg', 'lbfgs', 'saga', 'sag']}]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = logistic_regression,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = k_Fold,\n",
    "                           n_jobs = -1)\n",
    "grid_search = grid_search.fit(X, Y)\n",
    "print(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To View the Results of the GridSearch\n",
    "pd.DataFrame(grid_search.cv_results_)[['mean_test_score', 'std_test_score', 'params']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To Identify the Best Accuracy and Best Features\n",
    "\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "\n",
    "print(\"BEST ACCURACY SCORE:\")\n",
    "print(best_accuracy)\n",
    "print('')\n",
    "\n",
    "print(\"BEST PARAMETERS:\")\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying RandomizedSearchCV to find the Best Parameters for the Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By contrast, Random Search sets up a grid of hyperparameter values and selects random combinations to train the model and score. This allows you to explicitly control the number of parameter combinations that are attempted. The number of search iterations is set based on time or resources. Scikit Learn offers the RandomizedSearchCV function for this process.\n",
    "\n",
    "While it’s possible that RandomizedSearchCV will not find as accurate of a result as GridSearchCV, it surprisingly picks the best result more often than not and in a fraction of the time it takes GridSearchCV would have taken. Given the same resources, Randomized Search can even outperform Grid Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Import the StratifiedKFold Class\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "k_Fold = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "# To Import the RandomizedSearchCV Class\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# To Set Parameters to be Optimized Under the Logistic Regression Model\n",
    "parameters = [{'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'penalty': ['l1'], 'solver': ['liblinear','saga']},\n",
    "              {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'penalty': ['l1', 'l2'], 'solver': ['newton-cg', 'lbfgs', 'saga', 'sag']}]\n",
    "\n",
    "#C = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "#penalty = ['l1', 'l2']\n",
    "#solver = ['newton-cg', 'lbfgs', 'saga', 'sag']\n",
    "#parameters = dict(C=C, penalty=penalty, solver=solver)\n",
    "\n",
    "randomized_search = RandomizedSearchCV(estimator = logistic_regression,\n",
    "                                       param_distributions = parameters,\n",
    "                                       n_iter = 50,\n",
    "                                       scoring = 'accuracy',\n",
    "                                       cv = k_Fold,\n",
    "                                       n_jobs = -1,\n",
    "                                       random_state = 0)\n",
    "best_fit = randomized_search.fit(X, Y)\n",
    "print(randomized_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To View the Results of the GridSearch\n",
    "pd.DataFrame(randomized_search.cv_results_)[['mean_test_score', 'std_test_score', 'params']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To Identify the Best Accuracy and Best Features\n",
    "\n",
    "best_accuracy = randomized_search.best_score_\n",
    "best_parameters = randomized_search.best_params_\n",
    "\n",
    "print(\"BEST ACCURACY SCORE:\")\n",
    "print(best_accuracy)\n",
    "print('')\n",
    "\n",
    "print(\"BEST PARAMETERS:\")\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### To Create New Logistic Regression Model Using the Optimal Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Instantiate the Model (Using the Optimized Parameters)\n",
    "logistic_regression = LogisticRegression(C=1000, penalty='l2', solver='newton-cg', random_state=0)\n",
    "\n",
    "# To Fit the Training Dataset into Logistic Regression Model\n",
    "logistic_regression.fit(X_train, Y_train)\n",
    "\n",
    "# To Predict the Output of the Testing Dataset\n",
    "Y_predict_LogReg = logistic_regression.predict(X_test)\n",
    "Y_predict_LogReg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### To Evaluate the Performance of the Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Show the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(Y_test, Y_predict_LogReg)\n",
    "\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(confusion_matrix, annot=True)\n",
    "plt.xlabel(\"Predicted Value\")\n",
    "plt.ylabel(\"Actual Value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the Classification Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "classification_accuracy = accuracy_score(Y_test, Y_predict_LogReg)\n",
    "print('Classification Accuracy: %.4f'\n",
    "      % classification_accuracy)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"CLASSIFICATION REPORT:\")\n",
    "print(classification_report(Y_test, Y_predict_LogReg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. To Create the K-Nearest Neighbors Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To Instantiate the Model (Using the Default Parameters)\n",
    "k_nearest_neighbors = KNeighborsClassifier()\n",
    "\n",
    "# To Fit the Training Dataset into K Nearest Neighbors Model\n",
    "k_nearest_neighbors.fit(X_train, Y_train)\n",
    "\n",
    "# To Predict the Output of the Testing Dataset\n",
    "Y_predict_KNN = k_nearest_neighbors.predict(X_test)\n",
    "Y_predict_KNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### To Evaluate the Performance of the K-Nearest Neighbors Machine Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To Show the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(Y_test, Y_predict_KNN)\n",
    "\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(confusion_matrix, annot=True)\n",
    "plt.xlabel(\"Predicted Value\")\n",
    "plt.ylabel(\"Actual Value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the Classification Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "classification_accuracy = accuracy_score(Y_test, Y_predict_KNN)\n",
    "print('Classification Accuracy: %.4f'\n",
    "      % classification_accuracy)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For the Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"CLASSIFICATION REPORT:\")\n",
    "print(classification_report(Y_test, Y_predict_KNN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying GridSearch to find the Best Parameters for the K-Nearest Neighbors Machine Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Import the kFold Class\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "k_Fold = StratifiedKFold (n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "# To Import the GridSearch Class\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# To Set Parameters to be Optimized Under the K Nearest Neighbors Model\n",
    "k_range = list(range(1, 51))\n",
    "weight = ['uniform', 'distance']\n",
    "algorithm = ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "leaf_size = [10, 20, 30, 40, 50, 60, 70, 80, 100]\n",
    "parameters = dict(n_neighbors=k_range, weights=weight, algorithm=algorithm, leaf_size=leaf_size)\n",
    "grid_search = GridSearchCV(estimator = k_nearest_neighbors,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = k_Fold,\n",
    "                           n_jobs = -1)\n",
    "grid_search = grid_search.fit(X, Y)\n",
    "print(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To View the Results of the GridSearch\n",
    "pd.DataFrame(grid_search.cv_results_)[['mean_test_score', 'std_test_score', 'params']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To Identify the Best Accuracy and Best Features\n",
    "\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "\n",
    "print(\"BEST ACCURACY SCORE:\")\n",
    "print(best_accuracy)\n",
    "print('')\n",
    "\n",
    "print(\"BEST PARAMETERS:\")\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### To Create New K-Nearest Neighbors Model Using the Optimal Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Instantiate the Model\n",
    "k_nearest_neighbors = KNeighborsClassifier(n_neighbors=4, weights='distance', algorithm='auto', leaf_size=10)\n",
    "\n",
    "# To Fit the Training Dataset into K Nearest Neighbors Model\n",
    "k_nearest_neighbors.fit(X_train, Y_train)\n",
    "\n",
    "# To Predict the Output of the Training Dataset\n",
    "Y_predict_KNN = k_nearest_neighbors.predict(X_test)\n",
    "Y_predict_KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### To Evaluate the Performance of the K-Nearest Neighbors Machine Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To Show the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(Y_test, Y_predict_KNN)\n",
    "\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(confusion_matrix, annot=True)\n",
    "plt.xlabel(\"Predicted Value\")\n",
    "plt.ylabel(\"Actual Value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the Classification Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "classification_accuracy = accuracy_score(Y_test, Y_predict_KNN)\n",
    "print('Classification Accuracy: %.4f'\n",
    "      % classification_accuracy)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For the Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"CLASSIFICATION REPORT:\")\n",
    "print(classification_report(Y_test, Y_predict_KNN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. To Create the Support Vector Machine Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Instantiate the Model (Using the Default Parameters)\n",
    "support_vector_machine = SVC(random_state=0)\n",
    "\n",
    "# To Fit the Training Dataset into Support Vector Machine Model\n",
    "support_vector_machine.fit(X_train, Y_train)\n",
    "\n",
    "# To Predict the Output of the Testing Dataset\n",
    "Y_predict_SVM = support_vector_machine.predict(X_test)\n",
    "Y_predict_SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### To Evaluate the Performance of the Support Vector Machine Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Show the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(Y_test, Y_predict_SVM)\n",
    "\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(confusion_matrix, annot=True)\n",
    "plt.xlabel(\"Predicted Value\")\n",
    "plt.ylabel(\"Actual Value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For the Classification Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "classification_accuracy = accuracy_score(Y_test, Y_predict_SVM)\n",
    "print('Classification Accuracy: %.4f'\n",
    "      % classification_accuracy)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"CLASSIFICATION REPORT:\")\n",
    "print(classification_report(Y_test, Y_predict_SVM))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying GridSearch to find the Best Parameters for the Support Vector Machine Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Import the kFold Class\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "k_Fold = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "# To Import the GridSearch Class\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# To Set Parameters to be Optimized Under the Support Vector Machine Model\n",
    "parameters = [{'C': [0.001, 0.01, 0.1, 10, 100, 1000], 'kernel': ['linear'], 'decision_function_shape' : ['ovo', 'ovr']},\n",
    "              {'C': [0.001, 0.01, 0.1, 10, 100, 1000], 'kernel': ['rbf'], 'gamma': [0.1, 0.5, 1, 5, 10], 'decision_function_shape' : ['ovo', 'ovr']},\n",
    "              {'C': [0.001, 0.01, 0.1, 10, 100, 1000], 'kernel': ['poly'], 'gamma': [0.1, 0.5, 1, 5, 10], 'degree': [2, 3, 4, 5], 'decision_function_shape' : ['ovo', 'ovr']},\n",
    "              {'C': [0.001, 0.01, 0.1, 10, 100, 1000], 'kernel': ['sigmoid'], 'gamma': [0.1, 0.5, 1, 5, 10]}]\n",
    "grid_search = GridSearchCV(estimator = support_vector_machine,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = k_Fold,\n",
    "                           n_jobs = -1)\n",
    "grid_search = grid_search.fit(X, Y)\n",
    "print(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other Parameters for SVM\n",
    "# To Set Parameters to be Optimized Under the Support Vector Machine Model\n",
    "#parameters = [{'C': [1, 10, 100, 1000], 'kernel': ['linear'], 'decision_function_shape' : ['ovo', 'ovr']},\n",
    "              #{'C': [1, 10, 100, 1000], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 1, 5, 10], 'decision_function_shape' : ['ovo', 'ovr']},\n",
    "              #{'C': [1, 10, 100, 1000], 'kernel': ['poly'], 'gamma': [0.1, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 1, 5, 10], 'degree': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], 'decision_function_shape' : ['ovo', 'ovr']},\n",
    "              #{'C': [1, 10, 100, 1000], 'kernel': ['sigmoid'], 'gamma': [0.1, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 1, 5, 10], 'decision_function_shape' : ['ovo', 'ovr']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To View the Results of the GridSearch\n",
    "pd.DataFrame(grid_search.cv_results_)[['mean_test_score', 'std_test_score', 'params']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "\n",
    "print(\"BEST ACCURACY SCORE:\")\n",
    "print(best_accuracy)\n",
    "print('')\n",
    "\n",
    "print(\"BEST PARAMETERS:\")\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### To Create New Support Vector Machine Model Using the Optimized Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Instantiate the Model (Using the Optimized Parameters)\n",
    "state_vector_machine = SVC(C=0.001, decision_function_shape='ovo', gamma=10, kernel='poly', degree=4, random_state=0)\n",
    "\n",
    "# To Fit the Training Dataset into Support Vector Machine Model\n",
    "state_vector_machine.fit(X_train, Y_train)\n",
    "\n",
    "# To Predict the Output of the Training Dataset\n",
    "Y_predict_SVM = state_vector_machine.predict(X_test)\n",
    "Y_predict_SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Show the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(Y_test, Y_predict_SVM)\n",
    "\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(confusion_matrix, annot=True)\n",
    "plt.xlabel(\"Predicted Value\")\n",
    "plt.ylabel(\"Actual Value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the Classification Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "classification_accuracy = accuracy_score(Y_test, Y_predict_SVM)\n",
    "print('Classification Accuracy: %.4f'\n",
    "      % classification_accuracy)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"CLASSIFICATION REPORT:\")\n",
    "print(classification_report(Y_test, Y_predict_SVM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Dr. Robert G. de Luna, PECE\n",
    "robert.deluna@dlsl.edu.ph / robert_g_deluna@dlsu.edu.ph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
